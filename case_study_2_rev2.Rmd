---
title: "case_study_2"
author: "Travis Deason"
date: "12/4/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}
rm( list = ls()); cat("\014")  # Clear environment
set.seed(66)
#install.packages('tidyr')
#install.packages('dplyr')
#install.packages('ggplot2')
#install.packages('Hmisc')
#install.packages('plotly')
#install.packages('stringr)
library(stringr)
library(plotly)
library(Hmisc)
library(tidyr)
library(dplyr)
library(ggplot2)
library(MASS)
require(plyr)
source('src/deason_functions.R')
data <- read.csv('data/CaseStudy2-data.csv')
data$Department <- revalue(data$Department, c('Human Resources' = 'Human Resources', 'Research & Development'='Research/Development', 'Sales'='Sales'))
describe_data <- read.csv('data/CaseStudy2-descriptions.csv')
#names(describe_data) <- (names(describe_data), tolower)
names(data) <- sapply(names(data), tolower)
```
## Project Goals

* Identify (at least) the top three factors that contribute to turnover.

* Learn about any job role specific trends that may exist in the data set

* Provide any other interesting trends and observations from your analysis

* Because we have a mix of catagoriacal and numerical data in here, We will split every integer column into binned values

```{r}
#function defined in deason_functions.R
data_binned <- bin_columns(data, 100, 10)
```



* Now, lets find out the base attrition rate

```{r}
na_count <- sum(is.na(data$attrition))
## convert data Attrition to binary
data_binned$attrition <- data$attrition == 'Yes'
data$attrition <- data_binned$attrition
#data_binned$attrition <- data_binned$attrition * 100
## N/A Count
print(sum(na_count))
## Sum of Employees who quit
print(sum(data_binned$attrition))
## retain ratio
overall_ratio <- sum(data_binned$attrition) / length(data_binned$attrition)
print(overall_ratio)
```


* So, there are no N/A values in attrition
* 237 total employees quit out of 1470 total (which is 16.122 percent)


* Now (Since we have binned all continous values) lets treat all values as catagorical, and find out which of them have a higher then expected corelation with

* First we will create a vector which contains the lengths of all catagories, or factors

```{r}
num_obs <- find_number_observations(data_binned, sep='&')
print(mean(num_obs))
length(num_obs)
obs_stacked = stack(num_obs)
ggplot(obs_stacked, aes(x = values)) +
  stat_density(position="identity",geom="line")
```

*It looks like we have 205 possible factors with an mean of 238 observations each, and most factors seem to have around ~170 variables, so we are fairly well distributed, but it would be nice if one of those factors with 1000+ had a zero attrition rate


```{r}
percent_pos <- find_percent(data_binned, 'attrition', num_obs)
print(mean(percent_pos))
print(median(percent_pos))
q90 <- quantile(percent_pos, .9)
per_stacked = stack(percent_pos)
ggplot(per_stacked, aes(x = values)) +
  stat_density(position="identity",geom="line")
percent_pos[percent_pos > q90] * 100
#percent_pos[order(-percent_pos)] * 100
```

* Unsuprisingly, our mean value for percent_quit is exactly in line with the overall percent who quit, but the median value is notably lower, and we seem to have a small cluster of events hovering around .33% quit; which is approximitly double the standard rate.  There may be a strong predictive power in this group of variables.

* Let's take a closer look at some of them

```{r}
## move all our data into a dataframe of percent_quit verses number of observations
attr_frame <- data.frame(percent_pos, num_obs)
hnames <- (rownames(attr_frame) != 'attrition&TRUE' & rownames(attr_frame) != 'attrition&FALSE')
attr_frame <- attr_frame[hnames,]
high_prob <- subset(attr_frame, percent_pos > overall_ratio)
high_prob$ratio_delta = high_prob$percent_pos - overall_ratio
hnames <- (rownames(high_prob) != 'attrition&TRUE' & rownames(high_prob) != 'attrition&FALSE')
high_prob <- high_prob[hnames,]
head(high_prob[order(-high_prob$ratio_delta),], 13)
```

* It looks like you can predict that there is a 40% an employee will quit if they are a sales representative, if they are in thier first 4 working years, or they have been at the company for less then 2 years.  Overall there seems to be a strong coorlation between quitting and youth at this company.  Additionally, it seems employees who work too many hours, too much overtime, or consider thier workplace to have a poor work life balance can be considered high risk.

```{r}
tail(high_prob[order(-high_prob$ratio_delta),], 13)
```


* On the other side of things, the data seems to indicate that there is a very strong coorelation between employee retention and how long an employee has been in a specific role.  That and higher income, and more senior employees in their late 30s to mid 40s tend to stick around longer.

* Another thing we might be interested in is how strongly coorelated our most influencial variables are to our overall model.


```{r}
source('src/deason_functions.R')
# Generate covariance matrix for all high attrition attributes.
over_30 <- subset(high_prob, percent_pos > .30)
tups <- str_split(row.names(over_30), pattern='&')
first_cell <- function(x){x[1]}
use_cols <- unique(sapply(tups, first_cell))
dummy_30 <- make_dummy(data_binned, subcols=use_cols, drop_others=TRUE)
#cols <- row.names(over_30)
#dummy_sub <- data_dummy[,cols]
covar_30 <- find_covariance(dummy_30, names(dummy_30))
covar_30[1:15]
```


* It looks like most employees who do not work overtime have a good work life balance, most employees who have worked less then 2 years have had thier manager for less then a year (75%); which may be an indication that new employees tend to get managers shifted often, or many new employees quit bedore they have been around a year.  and we also see that new employees are on the low end of the salary range, and managers have typically been at the company a long time.  Overall, i would say these highly predictive variables are less strongly coorelated then i expected.

*just for fun, let's see if we can find the most commonly correlated variables throughout the table

```{r}
data_dummy <- make_dummy(data_binned)
all_covar <- find_covariance(data_dummy, names(data_dummy))
length(all_covar)
```

* since it would be hard to look at all 7700 covariaraiant pairs, It's probably a good idea to look at the histogram to see where most pairs lie

```{r}
hist(all_covar, breaks=50)
```


* It looks like most of our variables are pretty independent of the others.  I think a good place to start would be to see some of the items with a correlation of .6 or higher.


```{r}
head(all_covar[all_covar > .60 & all_covar < .999], 13)
#sum(data_dummy[,'performancerating&3']) / 1470
print(sum(data[,'performancerating'] == 3))
sum(data[,'performancerating'] == 3 & data_binned[,'attrition'] == TRUE)
```

* So, we do have a strong coorelation between attriton and being over 18, but that isn't really relevant since all employees are over 18.  There's a couple other obvious coorelations up there as well, but I don't really see anything that stands out as being a strong predictor.

## Linear Model For Predicting Employee Retention

* We are going to try to build a model using linear regression.  Since linear regression isn't typically used for classification, we will be coxing the model into making predictions.  Since the source code for this operation gets a little cumbersome, it it will retained in the source directory.

* The goal is to change the label value to have a score from 0-100 (since all labels are binary, they will either be 1 or 100).  We will then use some of the feature generation techniques to collect some variables we may find interesing.  Then, using a train-test-split, we will test our model against a reserved subset of the data-set.

* Since the goal is classification, we will be using a threshold value to measure model performance.  The other hyper-parameter we will be tuning is the percentage of total variables we will be using in the dataframe.  Both of these values with thier predictive outputs are plotted below.

```{r}
threslist <- c()
m_perf <- c()
for(ivar in 100:950 / 10){
  sub_df <- gen_train_frame(data, 'attrition')
  reg_df <- subset_use_cols(data_binned, sub_df, 'attrition', min_qt=0.39)
  dfd <- featurize_frame(reg_df, 'attrition')
  fit <- lm(attrition~. , data=dfd[dfd[,'train'] == TRUE,])
  df.te <- but_I_regress(dfd, fit, 'attrition', thres=ivar)
  perf <- sum((df.te[,'correct']) / dim(df.te)[1])[1]
  m_perf <- append(m_perf, perf)
  threslist <- append(threslist, ivar)
}

out_vars <- data.frame(threslist, m_perf)
row.names(out_vars) <- threslist
```

## plot of model accuracy vs percentage of variables included in the frame

```{r}
out_vars[out_vars[,'m_perf'] == max(out_vars[,'m_perf']),]
ggplot(data=out_vars, aes(x=threslist, y=m_perf)) + geom_point()
```



```{r}
varquant <- c()
m_perf <- c()
for(ivar in 100:950 / 1000){
  sub_df <- gen_train_frame(data, 'attrition')
  reg_df <- subset_use_cols(data_binned, sub_df, 'attrition', min_qt=ivar)
  dfd <- featurize_frame(reg_df, 'attrition')
  #names(dfd)
  fit <- lm(attrition~. , data=dfd[dfd[,'train'] == TRUE,])
  df.te <- but_I_regress(dfd, fit, 'attrition', thres=74)
  perf <- sum((df.te[,'correct']) / dim(df.te)[1])[1]
  m_perf <- append(m_perf, perf)
  varquant <- append(varquant, ivar)
}

vqnt.df <- data.frame(varquant, m_perf)
row.names(vqnt.df) <- varquant
```


## Plot of model accuracy vs threshold value

```{r}
row.names(vqnt.df) <- varquant
#vqnt.df[vqnt.df[,m_perf] == max(vqnt.df[,m_perf])]
print(vqnt.df[vqnt.df[,'m_perf'] == max(vqnt.df[,'m_perf']),])
ggplot(data=vqnt.df, aes(x=varquant, y=m_perf)) + geom_point()
```

* Unfortunatly, It doesn't look like adding and subtracting variables has any effect on model performance; which is a little weird, but the chart above seems to show a completley random cloud; so our final model is about 55% accurate at measuring employee retention; which is probably an indication that it just doesn't make a whole lot of sese to use linear-regression for classification.

## Now we will investigate some other variables.

* Now let's take a look at enviroment satisfaction.  This varaible is catagorized from 1-4, but I would like to convert it to a binary varaible, so I am going to look to see how it's distributed

* It looks like 40% of all employees would rank their workplace as low or medium, and they are fairly evenly distributed; so I am going to change the environmentsatisfaction varaible so that any ratign of 1-2 is FALSE, and a rating of 3-4 is TRUE.

```{r}
data_binned[,'environmentsatisfaction'] <- data['environmentsatisfaction'] < 3
infl <- check_label_corelation(data_binned, 'environmentsatisfaction', '&', sd_ratio=.75)
infl
```

* It looks the the features most highly coorelated with environment satisfaction are a high monthly salary, having worked at one other company before, being at a company for a long time, feeling involved at your company, and having quit your job.  It seems to also help if you are a research director


* Moving onto education, we are presented with more evidence that this sample is not indicitive of the population.  Only 11 percent of those surveyed do not have a college degree, and .65 percent have a masters degree or higher; so because of our parciluar population, we are going to make the split at graduate school (so all employees with a masters degree or higher will be associated with the label TRUE)


```{r}
source('src/deason_functions.R')
data_binned[,'education'] <- data['education'] > 3
infl <- check_label_corelation(data_binned, 'education', '&', sd_ratio=.6)
infl
```


* The most interesting thing  here is that it seems .85% of those educated in HR have a masters degree or higher.  Also interesting is the fact that highly education people have typically worked at more companies in the past.  The large percentage of strong coorelations here may have more to do with the aundance of highly educated people at this company.  If we only look at employees with a PHD or higher, we find employees age 32-35, and age 51-60 are common here, also high income earners, and those who have worked at 9 companies before.


* Moving onto relationship satisfaction, it looks like 60% of people claim to be happy in thier relationship, so I am going to split this one up at the same place we've split the last two.  In this case we will say True if a relationship is at least a level 3 in satisfaction (or high).

```{r}
data_binned[,'relationshipsatisfaction'] <- data['relationshipsatisfaction'] == 4
infl <- check_label_corelation(data_binned, 'relationshipsatisfaction', '&', sd_ratio=.5)
infl
```

* Once agian human resources is right there at the top of our list both in job role, department, and education field, so apparently everyone in our test set who works in eduacation has a masters degree or higher.  If we only look at employees who have a relationship satisfaction of 4 or higher, we find that a dispropotionate amount of the employees who are new to their role are are happy in thier relationships.  This may be an indication that the job is hard on relationships.  We also find those who do less trainings are more happy in thier relationships, and those in higher job levels as well.



```{r}
sum(data['worklifebalance'] == 1) / 1470
sum(data['worklifebalance'] == 2) / 1470
sum(data['worklifebalance'] == 3) / 1470
sum(data['worklifebalance'] == 4) / 1470
```

* Moving onto work life balance, it looks like 60% of claim to have a good work life balance, so I am not interested in them  I am interested in the two extremes; because they seem to both have a smaller group.  First I am going to look at those who have a very good work life balance.

```{r}
data_binned[,'worklifebalance'] <- data['worklifebalance'] > 3
infl <- check_label_corelation(data_binned, 'worklifebalance', '&', sd_ratio=.7)
infl
```

* I am begining to think this dataset was put together by the Human Resources department, because it seems to paint thier job in a favorable light.  Those with an HR job role report a strong work-life balance at twice the rate of the population.  It also seem like work life balance is easier to obtain when you are older, it isn't your first company and you are very well paid.


```{r}
source('src/deason_functions.R')
data_binned[,'worklifebalance'] <- data['worklifebalance'] == 1
infl <- check_label_corelation(data_binned, 'worklifebalance', '&', sd_ratio=1.5)
infl
```

* Apparently a bad work life balance causes you to quit, and oddly, an education in Human Resources leads to a poor work life balance, while a job title in Human Resouces leads to a great work life balance.  medium-low wage workers seem to have a poor work life balance, and if you are jumping around jobs a lot you probably don't have a great work-life balance



## Linear model For Prediciting Employee Education Level

* Fully aware that our model doesn't seem to work, we decided it wouldn't hurt to try to model another factor.  This time we are going to try to predict if an employee has a pHD.

```{r}

varquant <- c()
m_perf <- c()
for(ivar in 100:950 / 1000){
  #data$education <- data$education == 4
  sub_df <- gen_train_frame(data, 'education')
  reg_df <- subset_use_cols(data_binned, sub_df, 'education', min_qt=ivar)
  dfd <- featurize_frame(reg_df, 'education')
  fit <- lm(education~. , data=dfd[dfd[,'train'] == TRUE,])
  df.te <- but_I_regress(dfd, fit, 'education', thres=74)
  perf <- sum((df.te[,'correct']) / dim(df.te)[1])[1]
  m_perf <- append(m_perf, perf)
  varquant <- append(varquant, ivar)
}

vqnt.df <- data.frame(varquant, m_perf)
row.names(vqnt.df) <- varquant
```
## plot of model accuracy vs percentage of variables included in the frame

```{r}
vqnt.df <- data.frame(varquant, m_perf)
out_vars[out_vars[,'m_perf'] == max(out_vars[,'m_perf']),]
ggplot(data=vqnt.df, aes(x=varquant, y=m_perf)) + geom_point()
```



```{r}
threslist <- c()
m_perf <- c()
for(ivar in 100:950 / 10){
  #data$education <- data$education == 4
  sub_df <- gen_train_frame(data, 'education')
  reg_df <- subset_use_cols(data_binned, sub_df, 'education', min_qt=.60)
  dfd <- featurize_frame(reg_df, 'education')
  fit <- lm(education~. , data=dfd[dfd[,'train'] == TRUE,])
  df.te <- but_I_regress(dfd, fit, 'education', thres=ivar)
  perf <- sum((df.te[,'correct']) / dim(df.te)[1])[1]
  m_perf <- append(m_perf, perf)
  threslist <- append(threslist, ivar)
}

out_vars <- data.frame(threslist, m_perf)
row.names(out_vars) <- threslist
```

## Plot of model accuracy vs threshold value

```{r}
print(out_vars[out_vars[,'m_perf'] == max(out_vars[,'m_perf']),])
ggplot(data=out_vars, aes(x=threslist, y=m_perf)) + geom_point()
```

* This looks like a nail in the coffin for linear-regression as a classifier.  Our model for predicting if an employee has a pHD is exactly as good as flipping a coin.


